# 人工智能：数据与模型安全

第一版：[ai-data-model-safety.github.io](https://ai-data-model-safety.github.io/)

人工智能真的安全吗？数据是否干净？模型是否可信？

<p align="center">
  <img width="350"  src="./_static/myfrontpage/_images/front.png">
</p>

<h5 align="center"><i>变色龙是丛林伪装大师，可以通过改变肤色来伪装和保护自己，代表着“变化”“适应”与“保护”，寓意安全防护的动态特性，需要适应复杂多变的外部环境。</i></h5>

本书聚焦学术前沿，围绕人工智能的两大核心要素，即数据和模型，系统深入地介绍相关安全问题和攻防算法。

本书的特色包括：

- **深入**：详细讲解各类攻防算法及其背后的对抗和鲁棒优化思想
- **系统**：全面梳理介绍人工智能数据与模型面临的各类安全风险
- **前沿**：覆盖人工智能安全领域最前沿的攻防技术及其发展动态

**本书适合人工智能、智能科学与技术、计算机科学与技术、软件工程、信息安全等专业的高年级本科生、研究生以及人工智能从业者阅读。** 通过本书，读者可以了解人工智能安全这一新兴领域，培养致力于发展“安全”“可信”人工智能的社会责任感。

## 课程内容

[课程主页](https://trust-ml.github.io/) | [课件](https://github.com/ai-data-model-safety/ai-data-model-safety.github.io/tree/dev/slides)

| 序号 | 主题                                                         |
| ---- | ------------------------------------------------------------ |
| 1    | [课程介绍&机器学习基础](https://github.com/ai-data-model-safety/ai-data-model-safety.github.io/blob/dev/slides/第1周：课程介绍%26机器学习基础.pptx) |
| 2    | [可解释性和普通鲁棒性](https://github.com/ai-data-model-safety/ai-data-model-safety.github.io/blob/dev/slides/第2周：可解释性和普通鲁棒性.pptx) |
| 3    | [对抗样本](https://github.com/ai-data-model-safety/ai-data-model-safety.github.io/blob/dev/slides/第3周：对抗样本.pptx) |
| 4    | [对抗样本检测](https://github.com/ai-data-model-safety/ai-data-model-safety.github.io/blob/dev/slides/第4周：对抗样本检测.pptx) |
| 5    | [对抗防御](https://github.com/ai-data-model-safety/ai-data-model-safety.github.io/blob/dev/slides/第5周：对抗防御.pptx) |
| 6    | [数据投毒和防御](https://github.com/ai-data-model-safety/ai-data-model-safety.github.io/blob/dev/slides/第6周：数据投毒和防御.pptx) |
| 7    | [后门攻击和防御](https://github.com/ai-data-model-safety/ai-data-model-safety.github.io/blob/dev/slides/第7周：后门攻击和防御.pptx) | 
| 8    | [数据抽取和模型窃取](https://github.com/ai-data-model-safety/ai-data-model-safety.github.io/blob/dev/slides/第8周：数据抽取和模型窃取.pptx) |
| 9    | [隐私攻击和防御](https://github.com/ai-data-model-safety/ai-data-model-safety.github.io/blob/dev/slides/第9周：隐私攻击和防御.pptx) |
| 10   | [深度伪造与检测](https://github.com/ai-data-model-safety/ai-data-model-safety.github.io/blob/dev/slides/第10周：深度伪造与检测.pptx) |
| 11   | [联邦学习](https://github.com/ai-data-model-safety/ai-data-model-safety.github.io/blob/dev/slides/第11周：联邦学习.pptx) |
| 12   | [AI模型版权保护](https://github.com/ai-data-model-safety/ai-data-model-safety.github.io/blob/dev/slides/第12周：AI模型版权保护.pptx) |
| 13   | [AI公平性与伦理](https://github.com/ai-data-model-safety/ai-data-model-safety.github.io/blob/dev/slides/第13周：AI公平性与伦理.pptx) |

